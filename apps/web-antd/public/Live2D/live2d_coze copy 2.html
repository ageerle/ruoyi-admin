<head>
  <!-- 引入Live2D核心依赖 -->
  <script src="./js/live2dcubismcore.min.js"></script>  <!-- Live2D Cubism核心运行库 -->
  <script src="./js/live2d.min.js"></script>            <!-- Live2D模型渲染主库 -->
  <script src="./js/pixi.min.js"></script>              <!-- Pixi.js图形渲染引擎（用于2D渲染） -->
  
  <!-- Cubism 4模型支持库（仅需Cubism 4模型时引入） -->
  <script src="./js/cubism4.min.js"></script>
  
  <!-- jQuery库（简化DOM操作和AJAX请求） -->
  <script src="./js/jquery-3.1.1.min.js"></script>
  
  <!-- Axios库（用于HTTP请求，替换了原CDN版本为本地文件） -->
  <script src="./js/axios.min.js"></script>

  <!-- 新增美化样式（保留原始注释） -->
  <style>
    .chat-output {
      display: flex;
      align-items: flex-end;
      gap: 10px;
      /* margin: 10px 0; */
    }

    #control {
      position: fixed;
      top: 20px;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(30, 30, 30, 0.9);
      padding: 20px;
      border-radius: 15px;
      box-shadow: 0 0 15px rgba(0,0,0,0.3);
      z-index: 1000;
      color: white;
      font-family: 'Segoe UI', sans-serif;
      /* 原始注释保留：控制面板样式：绝对定位（顶部50px，左侧50px），白色文字，字体大小18px */
      font-size: 18px;
    }

    .control-group {
      margin-bottom: 15px;
    }

    label {
      display: block;
      margin-bottom: 5px;
      font-size: 14px;
      font-weight: 500;
    }

    input[type="text"],
    input[type="search"],
    input[type="color"],
    select {
      width: 180px;
      padding: 8px;
      border: 1px solid #555;
      border-radius: 5px;
      background: #444;
      color: white;
      margin-right: 8px;
    }

    input[type="radio"] {
      margin-right: 5px;
    }

    button {
      padding: 10px 20px;
      border: none;
      border-radius: 5px;
      background: #4CAF50;
      color: white;
      cursor: pointer;
      transition: background 0.3s;
    }

    button:hover {
      background: #45a049;
    }

    button:active {
      transform: scale(0.95);
    }

    /* 隐藏元素优化 */
    [style*="display: none"],
    .off-screen {
      display: none !important;
    }

    #text_talk {
      width: 300px;
      height: 100px;
      padding: 8px;
      margin: 10px 0;
      border: 1px solid #555;
      border-radius: 5px;
      background: #444;
      color: white;
      resize: vertical;
    }
  </style>
</head>

<body>
  <!-- 模型显示画布（Live2D模型将渲染在此区域） -->
  <canvas id="canvas"></canvas>

  <!-- 交互控制面板（包含所有功能配置项） -->
  <div id="control">
    <!-- 测试音频按钮（触发模型口型同步播放） -->
    <button id="play">测试音频</button>
    <br />

    <!-- 模型切换组件 -->
    <!-- <label>数字人模型</label> -->
    <!-- 动态填充的模型列表下拉框 -->
    <!-- <select id="model_list"></select> -->
    <!-- 切换模型的触发按钮 -->
    <!-- <button id="update_model">更新模型</button>  -->
    <!-- <br /> -->

    <!-- 眼神跟随控制（通过单选框切换） -->
    <!-- <label>眼神跟随鼠标</label> -->
    <!-- 默认勾选"跟随鼠标" -->
    <!-- <input type="radio" name="eyes" value="true" checked>  -->
    <!-- <label>跟随鼠标</label> -->
    <!-- <input type="radio" id="option2" name="eyes" value="false"> -->
    <!-- <label>前方直视</label> -->
    <!-- <br /> -->

    <!-- 背景控制（颜色/图片切换） -->
    <label>背景控制</label>
    <input type="radio" id="option1" name="options" value="bg_color" checked>
    <label for="option1">背景颜色</label>
    <input id="bg_color" type="text" style="width:100px;"> <!-- 颜色值输入框（如"gray"或"#ff0000"） -->
    <br />
    <input type="radio" id="option2" name="options" value="bg_img">
    <label for="option2">背景图片</label>
    <input type="file" id="imgupload" style="display:none" /> <!-- 隐藏的文件选择框（用于上传背景图） -->
    <button id="openImgUpload">上传图片</button> <!-- 触发文件选择的按钮 -->
    <button id="update_bg">更新背景</button> <!-- 应用背景设置的按钮 -->
    <br />

    <!-- 语音合成接口配置 -->
    <label style="display: none;">语音接口地址</label>
    <!-- 语音合成服务地址 -->
    <input type="search" id="apiurl" style="display: none; width:200px;" value="http://127.0.0.1:9880"> 
    <br style="display: none;" />
    <label style="display: none;">推理文本语言种类</label>
    <!-- 待合成文本的语言（如"zh"中文） -->
    <input type="search" id="text_lang" style="display: none;  width:200px;" value="zh"> 
    <br style="display: none;" />
    <label style="display: none;">参考音频</label>
    <!-- 语音克隆的参考音频路径 -->
    <!-- <input type="search" id="ref_audio_path" style="width:200px;" value="./Keira.wav">   -->
    <input type="search" id="ref_audio_path" style="display: none; width:200px;" value="./meiduo.wav"> 
    <br style="display: none;" />
    <label style="display: none;">参考音频文本</label>
    <input type="search" id="prompt_text" style="display: none; width:300px;" value="你好呀，我叫暖暖，你看我这身白色毛衣"> <!-- 参考音频对应的文本 -->
    <br style="display: none;" />
    <label style="display: none;">参考音频文本语种</label>
    <input type="search" id="prompt_lang" style="display: none; width:200px;" value="zh"> <!-- 参考文本的语言 -->
    <br style="display: none;" />
    <label style="display: none;">切分方式</label>
    <input type="search" id="text_split_method" style="display: none; width:200px;" value="cut5"> <!-- 文本切分策略（如按5字切分） -->
    <br style="display: none;" />
    <label style="display: none;">语速</label>
    <input type="search" id="speed_factor" style="display: none; width:200px;" value="1.0"> <!-- 语速调节（1.0为正常） -->
    <br style="display: none;" />

    <!-- 大语言模型（LLM）对话配置 -->
    <!-- <label>ollama接口地址</label> -->
    <!-- LLM服务地址 -->
    <!-- <input type="search" id="llmurl" style="width:300px;" value="http://localhost:11434/api/chat">  -->
    <!-- <label>模型名称</label> -->
    <!-- 使用的LLM模型名称 -->
    <!-- <input id="model_name" value="deepseek-r1:7b">  -->
    <!-- <br /> -->
    <!-- <label>引导词(以AI的视角)</label> -->
    <!-- AI角色设定提示词 -->
    <!-- <input id="role_card" style="width:300px;" value="我是AI数字人梅朵，负责大数据中心介绍">  -->
    <!-- <br /> -->
    <!-- 生成回复的最大token数 -->
    <!-- <label>对话长度</label><input id="tokens" value="50">  -->
    <!-- 模型输出随机性（0~1，越小越确定） -->
    <!-- <label>temperature温度</label><input id="temperature" value="0.5">  -->
    <!-- <br /> -->

    
    <br /><br />
    <!-- 聊天交互组件 -->
    <label style="display: none;">聊天文本</label>
    <input id="text" style="width:400px; height: 35px;" value="" placeholder="我是梅朵，请输入想要咨询的内容"> <!-- 用户输入的聊天内容 -->
    <button id="start_talk" style="margin-left: 10px;">发送消息</button> <!-- 触发聊天请求的按钮 -->
    <br /><br />
    <!-- 显示LLM回复和语音合成文本 -->
    <!-- <textarea id="text_talk" style="width:400px;height:200px;font-size:15px;"></textarea> -->
    <!-- 流式语音合成触发按钮 -->
    <!-- <button id="start_stream" style="display: none;">流式合成语音</button>  -->
    <!-- 全量语音合成触发按钮 -->
    <!-- <button id="start">并行合成语音</button> -->
    <!-- <button id="start">朗读内容</button> -->
    <div class="chat-output">
      <textarea id="text_talk" style="width:400px;height:200px;font-size:15px;margin-right: 10px;">
      </textarea> <!-- 显示LLM回复和语音合成文本 -->
      <button id="start">朗读内容</button>
    </div>
    
  </div>

  <script type="text/javascript">
    // 隐藏流式合成按钮（当前可能未启用）
    // $("#start_stream").hide()

    /* -------------------- Cookie 配置管理 -------------------- */
    // 眼神跟随状态变更时保存到Cookie并刷新页面
    $('input[name="eyes"]').click(function () {
      var radioValue = $("input[name='eyes']:checked").val(); // 获取选中的radio值（true/false）
      setCookie("eyes", radioValue, 1024); // 写入Cookie（有效期1024天）
      location.reload(); // 刷新页面应用新配置
    });

    // 上传背景图片按钮点击事件（触发隐藏的文件选择框）
    $('#openImgUpload').click(function () {
      $('#imgupload').trigger('click'); // 模拟点击文件选择框
    });

    // 文件选择完成后的上传逻辑
    $('#imgupload').on('change', function () {
      var formData = new FormData();
      formData.append('image', $(this)[0].files[0]); // 将选中的文件添加到表单

      // 发送POST请求到服务端上传接口
      $.ajax({
        url: '/upload', // 服务端上传接口地址
        type: 'POST',
        data: formData,
        processData: false, // 不自动处理FormData
        contentType: false, // 自动设置Content-Type为multipart/form-data
        success: function (data) {
          console.log('上传成功，文件名:', data.filename);
          setCookie("bg_img", data.filename, 1024); // 保存图片名到Cookie
          var radioValue = $("input[name='options']:checked").val(); // 获取当前背景类型（颜色/图片）
          setCookie("bg_con", radioValue, 1024); // 保存背景类型到Cookie
          location.reload(); // 刷新页面应用新背景
        }
      });
    });

    // 读取Cookie值（通用函数）
    function getCookie(name) {
      const value = "; " + document.cookie; // 拼接Cookie字符串
      const parts = value.split("; " + name + "="); // 按键名分割
      if (parts.length === 2) return parts.pop().split(";").shift(); // 提取键对应的值
      return null; // 未找到返回null
    }

    // 写入Cookie值（通用函数）
    function setCookie(name, value, days) {
      const date = new Date();
      date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000)); // 计算过期时间（毫秒）
      const expires = "expires=" + date.toUTCString(); // 转换为UTC时间字符串
      document.cookie = `${name}=${value};${expires};path=/`; // 写入Cookie（路径为根目录）
    }

    /* -------------------- 初始化配置加载 -------------------- */
    // 加载背景控制配置（从Cookie读取并设置单选框状态）
    const selectedValue = getCookie("bg_con");
    if (selectedValue) {
      const radioButtons = document.getElementsByName("options");
      radioButtons.forEach(radio => {
        radio.checked = (radio.value === selectedValue); // 选中与Cookie值匹配的radio
      });
    }

    // 加载眼神跟随配置（从Cookie读取并设置单选框状态）
    const eyesValue = getCookie("eyes");
    if (eyesValue) {
      const radioButtons = document.getElementsByName("eyes");
      radioButtons.forEach(radio => {
        radio.checked = (radio.value === eyesValue); // 选中与Cookie值匹配的radio
      });
    }

    // 初始化背景颜色输入框（默认gray，或从Cookie读取）
    if (getCookie("bg_color") === undefined) {
      $("#bg_color").val("gray"); // 无Cookie时设为默认值
    } else {
      $("#bg_color").val(getCookie("bg_color")); // 有Cookie时读取保存值
    }

    // 应用背景配置（颜色或图片）
    let radioValue = $("input[name='options']:checked").val();
    if (radioValue === "bg_color") {
      // 颜色背景：设置canvas的背景色
      $("#canvas").css("background-color", $("#bg_color").val());
    } else {
      // 图片背景：从Cookie读取图片名并设置背景图
      const bgImg = getCookie("bg_img");
      if (bgImg) {
        const imageUrl = `./uploads/${bgImg}`; // 拼接图片路径（假设上传到uploads目录）
        $("#canvas").css("background-image", `url(${imageUrl})`); // 设置背景图
      }
    }

    // 初始化眼神跟随开关状态（控制模型是否自动跟随鼠标）
    let eye_bool = true; // 默认开启眼神跟随
    if (getCookie("eyes") === "false") {
      eye_bool = false; // 从Cookie读取到"false"时关闭
    }

    /* -------------------- 模型列表动态加载 -------------------- */
    // 从后端获取模型列表（通过模板引擎注入的JSON字符串）
    var model_list = '<%-model_list%>'; // 示例：["Hiyori", "March 7th"]
    model_list = JSON.parse(model_list); // 转换为JavaScript数组

    // 当前选中的模型路径（通过模板引擎注入）
    var selected_model = '<%-model_path%>'; // 示例："Hiyori"

    // 填充模型下拉框（#model_list）
    var $select = $("#model_list");
    $select.empty(); // 清空原有选项
    $.each(model_list, function (index, value) {
      // 根据是否为当前模型添加selected属性
      const isSelected = (value === selected_model) ? "selected" : "";
      $select.append(`<option ${isSelected} value="${value}">${value}</option>`);
    });

    /* -------------------- Live2D模型初始化核心逻辑 -------------------- */
    const live2d = PIXI.live2d; // 从PIXI对象中获取Live2D模块

    (async function main() {
      // 创建Pixi.js应用（绑定canvas，配置透明背景并自动适配窗口大小）
      const app = new PIXI.Application({
        view: document.getElementById("canvas"), // 绑定到id为canvas的DOM元素
        autoStart: true, // 自动启动渲染循环
        resizeTo: window, // 自动适配窗口大小
        transparent: true, // 背景透明
        backgroundAlpha: 0, // 背景透明度（0为完全透明）
      });

      // 加载Live2D模型（路径由模板引擎动态注入，如"./models/Hiyori/Hiyori.model3.json"）
      const cubism4Model = `./models/${selected_model}/${selected_model}.model3.json`;
      var models = await Promise.all([
        live2d.Live2DModel.from(cubism4Model, { autoInteract: eye_bool }) // 加载模型（是否自动交互）
      ]);

      // 将模型添加到舞台并设置缩放、位置
      models.forEach((model) => {
        app.stage.addChild(model); // 将模型添加到渲染舞台

        // 计算模型缩放比例（适配窗口大小）
        const scaleX = innerWidth / model.width; // 窗口宽度与模型宽度的比例
        const scaleY = innerHeight / model.height; // 窗口高度与模型高度的比例
        model.scale.set(Math.min(scaleX, scaleY)); // 取较小的比例，确保模型完全显示

        model.y = innerHeight * 0.1; // 模型垂直位置（顶部留出10%窗口高度）
        draggable(model); // 启用模型拖拽功能
      });

      const model4 = models[0]; // 获取第一个模型实例（当前仅加载一个模型）
      model4.x = innerWidth / 2; // 模型水平居中

      // 模型点击交互事件（检测命中区域）
      model4.on("hit", (hitAreas) => {
        if (hitAreas.includes("Body")) { // 命中身体区域
          model4.motion("Tap"); // 播放"Tap"动画（如被点击的动作）
        }
        if (hitAreas.includes("Head")) { // 命中头部区域
          model4.expression(); // 切换表情（随机或按顺序切换预设表情）
        }
      });

      /* -------------------- 交互事件处理 -------------------- */
      // 更新背景按钮点击事件（保存配置并刷新）
      $("#update_bg").click(function () {
        var radioValue = $("input[name='options']:checked").val(); // 当前背景类型（颜色/图片）
        setCookie("bg_con", radioValue, 1024); // 保存背景类型到Cookie
        setCookie("bg_color", $("#bg_color").val(), 1024); // 保存颜色值到Cookie
        location.reload(); // 刷新页面应用新配置
      });

      // 更新模型按钮点击事件（通知后端切换模型并刷新）
      $("#update_model").click(function () {
        // 发送GET请求到服务端接口，传递选中的模型路径
        axios.get('/edit_config', {
          params: { "model_path": $("#model_list").val() } // 参数：选中的模型路径
        })
        .then(response => {
          console.log("模型更新成功:", response.data);
          location.reload(); // 刷新页面加载新模型
        })
        .catch(error => {
          console.error("模型更新失败:", error);
          alert("更新模型失败: " + error.message);
        });
      });

      // 测试音频按钮点击事件（播放测试音频并驱动模型口型）
      $("#play").click(function () {
        // talk(model4, "./Keira.wav"); // 调用talk函数（音频路径为"./Keira.wav"）
        talk(model4, "./meiduo.wav");
      });

      // 停止播放按钮点击事件（未在HTML中显示，可能预留功能）
      $("#stop").click(function () {
        model4.stopSpeaking(); // 停止模型当前的口型动画和音频播放
      });

      // 并行合成语音按钮点击事件（全量合成并播放）
      $("#start").click(function () {
        const text = $("#text_talk").val().trim(); // 获取待合成的文本
        if (!text) return; // 无文本时不执行

        $("#start").prop("disabled", true); // 禁用按钮防止重复提交

        // 发送POST请求到语音合成接口（超时5分钟）
        axios.defaults.timeout = 300000;
        axios.post($("#apiurl").val(), {
          text_lang: $("#text_lang").val(), // 文本语言（如"zh"）
          ref_audio_path: $("#ref_audio_path").val(), // 参考音频路径
          prompt_lang: $("#prompt_lang").val(), // 参考文本语言
          prompt_text: $("#prompt_text").val(), // 参考文本内容
          text_split_method: $("#text_split_method").val(), // 文本切分方式
          batch_size: 10, // 批量合成大小
          media_type: 'wav', // 输出格式（wav）
          speed_factor: $("#speed_factor").val(), // 语速
          text: text // 待合成的文本内容
        }, { responseType: 'arraybuffer' }) // 响应类型为二进制数据
        .then(response => {
          const audioBlob = new Blob([response.data], { type: 'audio/wav' }); // 转换为音频Blob
          const audioUrl = URL.createObjectURL(audioBlob); // 创建音频URL
          talk(model4, audioUrl); // 播放音频并驱动模型口型
          $("#start").prop("disabled", false); // 启用按钮
        })
        .catch(error => {
          console.error("语音合成失败:", error);
          $("#start").prop("disabled", false); // 启用按钮
        });
      });

      // 发送聊天消息按钮点击事件（调用LLM接口并流式获取回复）
      // $("#start_talk").click(async function () {
      //   const text = $("#text").val().trim(); // 获取用户输入的聊天内容
      //   if (!text) { alert("请输入聊天内容"); return; }

      //   $("#start_talk").prop("disabled", true); // 禁用按钮
      //   $("#text_talk").val(""); // 清空历史回复

      //   // 构造LLM请求数据（流式响应）
      //   const data = {
      //     "model": $("#model_name").val(), // LLM模型名称
      //     "stream": true, // 启用流式响应
      //     "messages": [
      //       { "role": "assistant", "content": $("#role_card").val() }, // AI角色设定
      //       { "role": "user", "content": text } // 用户输入的消息
      //     ],
      //     "options": {
      //       "num_keep": 5, // 保留的历史token数
      //       "num_predict": parseInt($("#tokens").val()), // 生成的最大token数
      //       "temperature": parseFloat($("#temperature").val()), // 输出随机性
      //       // 其他模型参数（如top_k、top_p等）
      //     }
      //   };

      //   // 发送POST请求到LLM接口
      //   const response = await fetch($("#llmurl").val(), {
      //     method: "POST",
      //     body: JSON.stringify(data),
      //     headers: { "Content-Type": "application/json" }
      //   });

      //   // 流式读取响应（逐块处理）
      //   const reader = response.body.pipeThrough(new TextDecoderStream()).getReader();
      //   while (true) {
      //     const { done, value } = await reader.read();
      //     if (done) { // 响应结束
      //       console.log("LLM响应完成");
      //       $("#start_talk").prop("disabled", false); // 启用按钮
      //       $("#start").click(); // 触发语音合成（回复完成后播放）
      //       break;
      //     }
      //     try {
      //       const parsed = JSON.parse(value); // 解析JSON数据
      //       if (parsed.message?.content) { // 提取回复内容
      //         $('#text_talk').val($('#text_talk').val() + parsed.message.content); // 拼接显示
      //       }
      //     } catch (error) {
      //       console.error("解析LLM响应失败:", error);
      //     }
      //   }
      // });

      // 发送聊天消息按钮点击事件（调用Coze接口）
      $("#start_talk").click(async function () {
        const userInput = $("#text").val().trim(); // 获取用户输入的聊天内容
        if (!userInput) { alert("请输入聊天内容"); return; }

        // 禁用按钮防止重复提交
        $("#start_talk").prop("disabled", true);
        $("#text_talk").val(""); // 清空历史回复

        // Coze接口配置（替换为你的实际值）
        const cozeApiUrl = "https://api.coze.cn/v3/chat"; // 或使用新会话（可省略conversation_id）
        const authorizationToken = "pat_cZdnzIJoZanHbggbqnykTEo44HoCVoh4ak9YON7PPZnkU16cSfJctmUQ72AjNaGk"; // 你的API密钥
        const botId = "7504596188201746470"; // 你的机器人ID

        try {
          // 发送POST请求到Coze接口（流式响应）
          const response = await fetch(cozeApiUrl, {
            method: "POST",
            headers: {
              "Authorization": `Bearer ${authorizationToken}`,
              "Content-Type": "application/json"
            },
            body: JSON.stringify({
              "bot_id": botId,
              "user_id": "7376476310010937396", // 替换为实际用户ID
              "stream": true, // 启用流式响应
              "auto_save_history": true,
              "additional_messages": [
                {
                  "role": "user",
                  "content": userInput,
                  "content_type": "text"
                }
              ]
            })
          });

          // 处理流式响应（逐事件解析）
          const reader = response.body.pipeThrough(new TextDecoderStream()).getReader();
          let fullAnswer = ""; // 完整回复内容

          while (true) {
            const { done, value } = await reader.read();
            if (done) { // 响应结束
              console.log("Coze响应完成");
              $("#start_talk").prop("disabled", false); // 启用按钮
              // 可选：触发语音合成（调用现有的#start按钮逻辑）
              if (fullAnswer) {
                $("#text_talk").val(fullAnswer); // 确保显示完整内容
                $("#start").click(); // 触发并行语音合成
              }
              break;
            }

            // 解析每一行SSE事件（格式：event: xxx\ndata: {...}\n\n）
            const lines = value.split("\n").filter(line => line.trim() !== "");
            for (const line of lines) {
              if (line.startsWith("event:")) {
                const eventType = line.replace("event:", "").trim();
                const dataLine = lines[lines.indexOf(line) + 1]; // 下一行是data
                if (dataLine?.startsWith("data:")) {
                  const data = JSON.parse(dataLine.replace("data:", "").trim());
                  
                  // 根据事件类型处理数据
                  switch (eventType) {
                    case "conversation.message.delta":
                      // 增量内容（逐字显示）
                      if (data.content_type === "text" && data.type === "answer") {
                        fullAnswer += data.content; // 拼接完整回复
                        $("#text_talk").val(fullAnswer); // 更新文本区域
                      }
                      break;
                    case "conversation.message.completed":
                      // 完整内容（最终确认）
                      if (data.type === "answer" && data.content_type === "text") {
                        fullAnswer = data.content; // 覆盖为最终内容（避免中间错误）
                        $("#text_talk").val(fullAnswer);
                      }
                      break;
                    case "conversation.chat.completed":
                      // 聊天会话完成（可选操作）
                      console.log("聊天会话完成，总token数：", data.usage.token_count);
                      break;
                    case "done":
                      // 流结束标记
                      console.log("流响应结束");
                      break;
                  }
                }
              }
            }
          }
        } catch (error) {
          console.error("Coze接口调用失败:", error);
          alert("聊天请求失败: " + error.message);
          $("#start_talk").prop("disabled", false); // 启用按钮
        }
      });

      // 流式合成语音按钮点击事件（预留功能，当前未完全实现）
      $("#start_stream").click(async function () {
        // 类似并行合成，但逐块接收音频数据并实时播放
        // （当前代码未完整实现，需结合服务端流式输出）
        console.log("流式合成暂未完全实现");
      });
    })();

    /* -------------------- 辅助函数 -------------------- */
    // 驱动模型口型与音频同步播放的函数
    function talk(model, audio) {
      // 可选参数配置：音量、表情、是否恢复默认表情、跨域设置
      const options = {
        volume: 1, // 音量（0.0~1.0）
        expression: 8, // 播放时使用的表情索引
        resetExpression: true, // 播放完成后恢复默认表情
        crossOrigin: "anonymous" // 跨域配置（用于非同源音频）
      };
      model.speak(audio, options); // 调用模型的speak方法
    }

    // 使模型可拖拽的函数（通过鼠标事件实现）
    function draggable(model) {
      model.buttonMode = true; // 鼠标悬停时显示手型指针
      model.on("pointerdown", (e) => { // 鼠标按下事件
        model.dragging = true; // 标记为拖拽状态
        model._pointerX = e.data.global.x - model.x; // 记录鼠标相对于模型的X偏移
        model._pointerY = e.data.global.y - model.y; // 记录鼠标相对于模型的Y偏移
      });
      model.on("pointermove", (e) => { // 鼠标移动事件
        if (model.dragging) { // 拖拽状态下更新模型位置
          model.position.x = e.data.global.x - model._pointerX; // 计算新的X坐标
          model.position.y = e.data.global.y - model._pointerY; // 计算新的Y坐标
        }
      });
      model.on("pointerupoutside", () => model.dragging = false); // 鼠标松开（外部）
      model.on("pointerup", () => model.dragging = false); // 鼠标松开（内部）
    }

    // 添加模型边框的辅助函数（调试用，可选）
    function addFrame(model) {
      const foreground = PIXI.Sprite.from(PIXI.Texture.WHITE); // 创建白色精灵
      foreground.width = model.internalModel.width; // 宽度与模型一致
      foreground.height = model.internalModel.height; // 高度与模型一致
      foreground.alpha = 0.2; // 透明度（20%）
      model.addChild(foreground); // 添加到模型子节点

      // 创建复选框控制边框显示（绑定到#control面板）
      checkbox("Model Frames", (checked) => (foreground.visible = checked));
    }

    // 创建复选框的辅助函数（通用）
    function checkbox(name, onChange) {
      const id = name.replace(/\W/g, "").toLowerCase(); // 生成唯一id
      let checkbox = document.getElementById(id);

      if (!checkbox) {
        // 动态创建复选框HTML
        const p = document.createElement("p");
        p.innerHTML = `<input type="checkbox" id="${id}"> <label for="${id}">${name}</label>`;
        document.getElementById("control").appendChild(p); // 添加到控制面板
        checkbox = p.firstChild; // 获取复选框元素
      }

      // 绑定change事件（触发回调）
      checkbox.addEventListener("change", () => onChange(checkbox.checked));
      onChange(checkbox.checked); // 初始状态触发
    }
  </script>

  <!-- 保留原始内联样式（仅调整定位相关属性） -->
  <style>
    #control {
      /* 原始定位样式保留，但被上方的fixed定位覆盖 */
      /* position: absolute;
      top: 50px;
      left: 50px; */
      color: white;
      font-size: 18px;
    }
  </style>
</body>
</html>